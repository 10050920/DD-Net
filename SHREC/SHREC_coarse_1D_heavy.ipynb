{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import glob\n",
    "import gc\n",
    "from utils import *\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "from keras.optimizers import *\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras.layers.core import *\n",
    "from keras.layers.convolutional import *\n",
    "from keras import backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config():\n",
    "    def __init__(self):\n",
    "        self.frame_l = 32 # the length of frames\n",
    "        self.joint_n = 12 # the number of joints\n",
    "        self.joint_d = 3 # the dimension of joints\n",
    "        self.clc_coarse = 14 # the number of coarse class\n",
    "        self.clc_fine = 28 # the number of fine-grained class\n",
    "        self.feat_d = 66\n",
    "        self.filters = 64\n",
    "        self.joint_ind = np.array([0,1,2,5,6,9,10,13,14,17,18,21])\n",
    "        self.data_dir = '/mnt/nasbi/homes/fan/projects/action/skeleton/data/SHREC/'\n",
    "C = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poses_diff(x):\n",
    "    H, W = x.get_shape()[1],x.get_shape()[2]\n",
    "    x = tf.subtract(x[:,:1,...],x[:,:-1,...])\n",
    "    x = tf.image.resize_nearest_neighbor(x,size=[H.value,W.value],align_corners=False) # should not alignment here\n",
    "    return x\n",
    "\n",
    "def pose_motion(P,frame_l):\n",
    "    P_diff_slow = Lambda(lambda x: poses_diff(x))(P)\n",
    "    P_diff_slow = Reshape((frame_l,-1))(P_diff_slow)\n",
    "    P_fast = Lambda(lambda x: x[:,::2,...])(P)\n",
    "    P_diff_fast = Lambda(lambda x: poses_diff(x))(P_fast)\n",
    "    P_diff_fast = Reshape((int(frame_l/2),-1))(P_diff_fast)\n",
    "    return P_diff_slow,P_diff_fast\n",
    "    \n",
    "def c1D(x,filters,kernel):\n",
    "    x = Conv1D(filters, kernel_size=kernel,padding='same',use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    return x\n",
    "\n",
    "def block(x,filters):\n",
    "    x = c1D(x,filters,3)\n",
    "    x = c1D(x,filters,3)\n",
    "    return x\n",
    "    \n",
    "def d1D(x,filters):\n",
    "    x = Dense(filters,use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    return x\n",
    "\n",
    "def build_FM(frame_l=32,joint_n=12,joint_d=3,feat_d=90,filters=16):   \n",
    "    M = Input(shape=(frame_l,feat_d))\n",
    "    P = Input(shape=(frame_l,joint_n,joint_d))\n",
    "    \n",
    "    diff_slow,diff_fast = pose_motion(P,frame_l)\n",
    "    \n",
    "    x = block(M,filters)\n",
    "    x = MaxPool1D(2)(x)\n",
    "    \n",
    "    x_d_slow = block(diff_slow,filters)\n",
    "    x_d_slow = MaxPool1D(2)(x_d_slow)\n",
    "    \n",
    "    x_d_fast = block(diff_fast,filters)\n",
    "   \n",
    "    x = concatenate([x,x_d_slow,x_d_fast])\n",
    "    x = block(x,filters*2)\n",
    "    x = MaxPool1D(2)(x)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    \n",
    "    x = block(x,filters*4)\n",
    "    x = MaxPool1D(2)(x)\n",
    "    x = SpatialDropout1D(0.2)(x)\n",
    "    \n",
    "    x = block(x,filters*8)\n",
    "    x = SpatialDropout1D(0.2)(x)\n",
    "    \n",
    "    return Model(inputs=[M,P],outputs=x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_AR_single(frame_l=32,joint_n=22,joint_d=3,feat_d=66,clc_num=14,filters=16):\n",
    "    M = Input(name='M', shape=(frame_l,feat_d))  \n",
    "    P = Input(name='P', shape=(frame_l,joint_n,joint_d)) \n",
    "    \n",
    "    FM = build_FM(frame_l,joint_n,joint_d,feat_d,filters)\n",
    "    \n",
    "    x = FM([M,P])\n",
    "\n",
    "    x = GlobalMaxPool1D()(x)\n",
    "    \n",
    "    x = d1D(x,128)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = d1D(x,128)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(clc_num, activation='softmax')(x)\n",
    "    \n",
    "    ######################Self-supervised part\n",
    "    model = Model(inputs=[M,P],outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "AR_single = build_AR_single(C.frame_l,C.joint_n,C.joint_d,C.feat_d,C.clc_coarse,C.filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "M (InputLayer)                  (None, 32, 66)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "P (InputLayer)                  (None, 32, 12, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_5 (Model)                 (None, 4, 512)       1669504     M[0][0]                          \n",
      "                                                                 P[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 512)          0           model_5[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 128)          65536       global_max_pooling1d_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 128)          512         dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_41 (LeakyReLU)      (None, 128)          0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 128)          0           leaky_re_lu_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 128)          16384       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 128)          512         dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_42 (LeakyReLU)      (None, 128)          0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 128)          0           leaky_re_lu_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 14)           1806        dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,754,254\n",
      "Trainable params: 1,749,390\n",
      "Non-trainable params: 4,864\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "AR_single.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#AR_single.load_weights('weights/coarse_heavy.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = pickle.load(open(C.data_dir+\"train.pkl\", \"rb\"))\n",
    "Test = pickle.load(open(C.data_dir+\"test.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without frame_sampling train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 20/1960 [00:00<00:09, 197.55it/s]/home/fan/anaconda3/envs/keras/lib/python3.6/site-packages/scipy/ndimage/interpolation.py:583: UserWarning: From scipy 0.13.0, the output shape of zoom() is calculated with round() instead of int() - for these inputs the size of the returned array has changed.\n",
      "  \"the returned array has changed.\", UserWarning)\n",
      "100%|██████████| 1960/1960 [00:06<00:00, 317.60it/s]\n"
     ]
    }
   ],
   "source": [
    "X_0 = []\n",
    "X_1 = []\n",
    "Y = []\n",
    "for i in tqdm(range(len(Train['pose']))): \n",
    "    p = np.copy(Train['pose'][i]).reshape([-1,22,3])[:,C.joint_ind,:]\n",
    "    p = zoom(p,target_l=C.frame_l,joints_num=C.joint_n,joints_dim=C.joint_d)\n",
    "    p = normlize_range(p)\n",
    "    \n",
    "    label = np.zeros(C.clc_coarse)\n",
    "    label[Train['coarse_label'][i]-1] = 1   \n",
    "\n",
    "    M = get_CG(p,C)\n",
    "\n",
    "    X_0.append(M)\n",
    "    X_1.append(p)\n",
    "    Y.append(label)\n",
    "\n",
    "X_0 = np.stack(X_0)  \n",
    "X_1 = np.stack(X_1) \n",
    "Y = np.stack(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 72/840 [00:00<00:03, 232.61it/s]/home/fan/anaconda3/envs/keras/lib/python3.6/site-packages/scipy/ndimage/interpolation.py:583: UserWarning: From scipy 0.13.0, the output shape of zoom() is calculated with round() instead of int() - for these inputs the size of the returned array has changed.\n",
      "  \"the returned array has changed.\", UserWarning)\n",
      "100%|██████████| 840/840 [00:02<00:00, 312.30it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test_0 = []\n",
    "X_test_1 = []\n",
    "Y_test = []\n",
    "for i in tqdm(range(len(Test['pose']))): \n",
    "    p = np.copy(Test['pose'][i]).reshape([-1,22,3])[:,C.joint_ind,:]\n",
    "    p = zoom(p,target_l=C.frame_l,joints_num=C.joint_n,joints_dim=C.joint_d)\n",
    "    p = normlize_range(p)\n",
    "    \n",
    "    label = np.zeros(C.clc_coarse)\n",
    "    label[Test['coarse_label'][i]-1] = 1   \n",
    "\n",
    "    M = get_CG(p,C)\n",
    "\n",
    "    X_test_0.append(M)\n",
    "    X_test_1.append(p)\n",
    "    Y_test.append(label)\n",
    "\n",
    "X_test_0 = np.stack(X_test_0) \n",
    "X_test_1 = np.stack(X_test_1)  \n",
    "Y_test = np.stack(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/200\n",
      "1960/1960 [==============================] - 5s 3ms/step - loss: 0.0290 - acc: 0.9985 - val_loss: 0.6357 - val_acc: 0.8464\n",
      "Epoch 2/200\n",
      "1960/1960 [==============================] - 0s 83us/step - loss: 0.1957 - acc: 0.9556 - val_loss: 0.5984 - val_acc: 0.8833\n",
      "Epoch 3/200\n",
      "1960/1960 [==============================] - 0s 80us/step - loss: 0.1157 - acc: 0.9791 - val_loss: 0.5002 - val_acc: 0.8881\n",
      "Epoch 4/200\n",
      "1960/1960 [==============================] - 0s 67us/step - loss: 0.1038 - acc: 0.9781 - val_loss: 0.6364 - val_acc: 0.8512\n",
      "Epoch 5/200\n",
      "1960/1960 [==============================] - 0s 67us/step - loss: 0.1671 - acc: 0.9582 - val_loss: 0.5396 - val_acc: 0.8857\n",
      "Epoch 6/200\n",
      "1960/1960 [==============================] - 0s 67us/step - loss: 0.1013 - acc: 0.9811 - val_loss: 0.7155 - val_acc: 0.8714\n",
      "Epoch 7/200\n",
      "1960/1960 [==============================] - 0s 78us/step - loss: 0.0907 - acc: 0.9821 - val_loss: 0.7588 - val_acc: 0.8643\n",
      "Epoch 8/200\n",
      "1960/1960 [==============================] - 0s 67us/step - loss: 0.0936 - acc: 0.9796 - val_loss: 0.7177 - val_acc: 0.8690\n",
      "Epoch 9/200\n",
      "1960/1960 [==============================] - 0s 67us/step - loss: 0.0842 - acc: 0.9837 - val_loss: 0.6465 - val_acc: 0.8726\n",
      "Epoch 10/200\n",
      "1960/1960 [==============================] - 0s 67us/step - loss: 0.0689 - acc: 0.9867 - val_loss: 0.5825 - val_acc: 0.8833\n",
      "Epoch 11/200\n",
      "1960/1960 [==============================] - 0s 65us/step - loss: 0.0579 - acc: 0.9959 - val_loss: 0.5494 - val_acc: 0.8881\n",
      "Epoch 12/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0555 - acc: 0.9908 - val_loss: 0.5316 - val_acc: 0.8917\n",
      "Epoch 13/200\n",
      "1960/1960 [==============================] - 0s 73us/step - loss: 0.0468 - acc: 0.9944 - val_loss: 0.5225 - val_acc: 0.8917\n",
      "Epoch 14/200\n",
      "1960/1960 [==============================] - 0s 67us/step - loss: 0.0496 - acc: 0.9934 - val_loss: 0.5161 - val_acc: 0.8952\n",
      "Epoch 15/200\n",
      "1960/1960 [==============================] - 0s 67us/step - loss: 0.0467 - acc: 0.9944 - val_loss: 0.5185 - val_acc: 0.8893\n",
      "Epoch 16/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0419 - acc: 0.9954 - val_loss: 0.5199 - val_acc: 0.8905\n",
      "Epoch 17/200\n",
      "1960/1960 [==============================] - 0s 67us/step - loss: 0.0400 - acc: 0.9969 - val_loss: 0.5211 - val_acc: 0.8893\n",
      "Epoch 18/200\n",
      "1960/1960 [==============================] - 0s 67us/step - loss: 0.0373 - acc: 0.9974 - val_loss: 0.5198 - val_acc: 0.8857\n",
      "Epoch 19/200\n",
      "1960/1960 [==============================] - 0s 67us/step - loss: 0.0356 - acc: 0.9959 - val_loss: 0.5185 - val_acc: 0.8905\n",
      "Epoch 20/200\n",
      "1960/1960 [==============================] - 0s 67us/step - loss: 0.0351 - acc: 0.9980 - val_loss: 0.5176 - val_acc: 0.8881\n",
      "Epoch 21/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0348 - acc: 0.9980 - val_loss: 0.5188 - val_acc: 0.8881\n",
      "Epoch 22/200\n",
      "1960/1960 [==============================] - 0s 70us/step - loss: 0.0327 - acc: 0.9990 - val_loss: 0.5198 - val_acc: 0.8869\n",
      "Epoch 23/200\n",
      "1960/1960 [==============================] - 0s 67us/step - loss: 0.0333 - acc: 0.9974 - val_loss: 0.5194 - val_acc: 0.8893\n",
      "Epoch 24/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0359 - acc: 0.9974 - val_loss: 0.5173 - val_acc: 0.8881\n",
      "Epoch 25/200\n",
      "1960/1960 [==============================] - 0s 67us/step - loss: 0.0308 - acc: 0.9969 - val_loss: 0.5124 - val_acc: 0.8881\n",
      "Epoch 26/200\n",
      "1960/1960 [==============================] - 0s 65us/step - loss: 0.0338 - acc: 0.9964 - val_loss: 0.5069 - val_acc: 0.8893\n",
      "Epoch 27/200\n",
      "1960/1960 [==============================] - 0s 67us/step - loss: 0.0319 - acc: 0.9969 - val_loss: 0.5006 - val_acc: 0.8893\n",
      "Epoch 28/200\n",
      "1960/1960 [==============================] - 0s 67us/step - loss: 0.0321 - acc: 0.9974 - val_loss: 0.4941 - val_acc: 0.8893\n",
      "Epoch 29/200\n",
      "1960/1960 [==============================] - 0s 67us/step - loss: 0.0314 - acc: 0.9980 - val_loss: 0.4868 - val_acc: 0.8952\n",
      "Epoch 30/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0300 - acc: 0.9985 - val_loss: 0.4790 - val_acc: 0.8988\n",
      "Epoch 31/200\n",
      "1960/1960 [==============================] - 0s 67us/step - loss: 0.0226 - acc: 0.9990 - val_loss: 0.4717 - val_acc: 0.8988\n",
      "Epoch 32/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0298 - acc: 0.9990 - val_loss: 0.4643 - val_acc: 0.9000\n",
      "Epoch 33/200\n",
      "1960/1960 [==============================] - 0s 65us/step - loss: 0.0273 - acc: 0.9990 - val_loss: 0.4569 - val_acc: 0.9012\n",
      "Epoch 34/200\n",
      "1960/1960 [==============================] - 0s 70us/step - loss: 0.0248 - acc: 1.0000 - val_loss: 0.4500 - val_acc: 0.9024\n",
      "Epoch 35/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0265 - acc: 0.9980 - val_loss: 0.4439 - val_acc: 0.9036\n",
      "Epoch 36/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0218 - acc: 0.9995 - val_loss: 0.4386 - val_acc: 0.9024\n",
      "Epoch 37/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0240 - acc: 1.0000 - val_loss: 0.4340 - val_acc: 0.9012\n",
      "Epoch 38/200\n",
      "1960/1960 [==============================] - 0s 70us/step - loss: 0.0228 - acc: 0.9995 - val_loss: 0.4297 - val_acc: 0.9024\n",
      "Epoch 39/200\n",
      "1960/1960 [==============================] - 0s 85us/step - loss: 0.0274 - acc: 0.9980 - val_loss: 0.4248 - val_acc: 0.9036\n",
      "Epoch 40/200\n",
      "1960/1960 [==============================] - 0s 66us/step - loss: 0.0238 - acc: 0.9995 - val_loss: 0.4203 - val_acc: 0.9036\n",
      "Epoch 41/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0249 - acc: 0.9985 - val_loss: 0.4162 - val_acc: 0.9048\n",
      "Epoch 42/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0230 - acc: 0.9990 - val_loss: 0.4128 - val_acc: 0.9060\n",
      "Epoch 43/200\n",
      "1960/1960 [==============================] - 0s 75us/step - loss: 0.0201 - acc: 0.9990 - val_loss: 0.4095 - val_acc: 0.9060\n",
      "Epoch 44/200\n",
      "1960/1960 [==============================] - 0s 82us/step - loss: 0.0227 - acc: 0.9995 - val_loss: 0.4066 - val_acc: 0.9095\n",
      "Epoch 45/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0231 - acc: 0.9995 - val_loss: 0.4035 - val_acc: 0.9107\n",
      "Epoch 46/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0231 - acc: 0.9990 - val_loss: 0.4006 - val_acc: 0.9119\n",
      "Epoch 47/200\n",
      "1960/1960 [==============================] - 0s 63us/step - loss: 0.0252 - acc: 0.9985 - val_loss: 0.3978 - val_acc: 0.9119\n",
      "Epoch 48/200\n",
      "1960/1960 [==============================] - 0s 67us/step - loss: 0.0228 - acc: 0.9980 - val_loss: 0.3951 - val_acc: 0.9143\n",
      "Epoch 49/200\n",
      "1960/1960 [==============================] - 0s 66us/step - loss: 0.0244 - acc: 0.9990 - val_loss: 0.3924 - val_acc: 0.9143\n",
      "Epoch 50/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0241 - acc: 0.9985 - val_loss: 0.3896 - val_acc: 0.9143\n",
      "Epoch 51/200\n",
      "1960/1960 [==============================] - 0s 67us/step - loss: 0.0244 - acc: 0.9985 - val_loss: 0.3873 - val_acc: 0.9143\n",
      "Epoch 52/200\n",
      "1960/1960 [==============================] - 0s 67us/step - loss: 0.0210 - acc: 1.0000 - val_loss: 0.3852 - val_acc: 0.9131\n",
      "Epoch 53/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0216 - acc: 0.9995 - val_loss: 0.3830 - val_acc: 0.9131\n",
      "Epoch 54/200\n",
      "1960/1960 [==============================] - 0s 69us/step - loss: 0.0235 - acc: 0.9995 - val_loss: 0.3809 - val_acc: 0.9143\n",
      "Epoch 55/200\n",
      "1960/1960 [==============================] - 0s 66us/step - loss: 0.0221 - acc: 0.9990 - val_loss: 0.3791 - val_acc: 0.9143\n",
      "Epoch 56/200\n",
      "1960/1960 [==============================] - 0s 67us/step - loss: 0.0200 - acc: 1.0000 - val_loss: 0.3772 - val_acc: 0.9143\n",
      "Epoch 57/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0201 - acc: 1.0000 - val_loss: 0.3755 - val_acc: 0.9143\n",
      "Epoch 58/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0194 - acc: 0.9995 - val_loss: 0.3737 - val_acc: 0.9143\n",
      "Epoch 59/200\n",
      "1960/1960 [==============================] - 0s 67us/step - loss: 0.0267 - acc: 0.9990 - val_loss: 0.3719 - val_acc: 0.9143\n",
      "Epoch 60/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0217 - acc: 1.0000 - val_loss: 0.3700 - val_acc: 0.9143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0201 - acc: 1.0000 - val_loss: 0.3683 - val_acc: 0.9143\n",
      "Epoch 62/200\n",
      "1960/1960 [==============================] - 0s 66us/step - loss: 0.0222 - acc: 0.9995 - val_loss: 0.3666 - val_acc: 0.9131\n",
      "Epoch 63/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0208 - acc: 0.9980 - val_loss: 0.3648 - val_acc: 0.9131\n",
      "Epoch 64/200\n",
      "1960/1960 [==============================] - 0s 69us/step - loss: 0.0235 - acc: 0.9990 - val_loss: 0.3634 - val_acc: 0.9143\n",
      "Epoch 65/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0205 - acc: 0.9990 - val_loss: 0.3621 - val_acc: 0.9143\n",
      "Epoch 66/200\n",
      "1960/1960 [==============================] - 0s 75us/step - loss: 0.0211 - acc: 0.9990 - val_loss: 0.3607 - val_acc: 0.9143\n",
      "Epoch 67/200\n",
      "1960/1960 [==============================] - 0s 76us/step - loss: 0.0229 - acc: 0.9990 - val_loss: 0.3594 - val_acc: 0.9155\n",
      "Epoch 68/200\n",
      "1960/1960 [==============================] - 0s 67us/step - loss: 0.0214 - acc: 1.0000 - val_loss: 0.3580 - val_acc: 0.9155\n",
      "Epoch 69/200\n",
      "1960/1960 [==============================] - 0s 66us/step - loss: 0.0197 - acc: 1.0000 - val_loss: 0.3568 - val_acc: 0.9155\n",
      "Epoch 70/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0211 - acc: 0.9990 - val_loss: 0.3555 - val_acc: 0.9155\n",
      "Epoch 71/200\n",
      "1960/1960 [==============================] - 0s 73us/step - loss: 0.0181 - acc: 1.0000 - val_loss: 0.3543 - val_acc: 0.9155\n",
      "Epoch 72/200\n",
      "1960/1960 [==============================] - 0s 71us/step - loss: 0.0201 - acc: 0.9990 - val_loss: 0.3532 - val_acc: 0.9155\n",
      "Epoch 73/200\n",
      "1960/1960 [==============================] - 0s 67us/step - loss: 0.0226 - acc: 0.9990 - val_loss: 0.3521 - val_acc: 0.9155\n",
      "Epoch 74/200\n",
      "1960/1960 [==============================] - 0s 67us/step - loss: 0.0223 - acc: 0.9980 - val_loss: 0.3511 - val_acc: 0.9155\n",
      "Epoch 75/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0246 - acc: 0.9990 - val_loss: 0.3502 - val_acc: 0.9155\n",
      "Epoch 76/200\n",
      "1960/1960 [==============================] - 0s 66us/step - loss: 0.0227 - acc: 0.9990 - val_loss: 0.3493 - val_acc: 0.9167\n",
      "Epoch 77/200\n",
      "1960/1960 [==============================] - 0s 67us/step - loss: 0.0211 - acc: 1.0000 - val_loss: 0.3484 - val_acc: 0.9143\n",
      "Epoch 78/200\n",
      "1960/1960 [==============================] - 0s 67us/step - loss: 0.0218 - acc: 0.9995 - val_loss: 0.3476 - val_acc: 0.9167\n",
      "Epoch 79/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0198 - acc: 1.0000 - val_loss: 0.3467 - val_acc: 0.9179\n",
      "Epoch 80/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0233 - acc: 0.9995 - val_loss: 0.3459 - val_acc: 0.9179\n",
      "Epoch 81/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0216 - acc: 1.0000 - val_loss: 0.3451 - val_acc: 0.9179\n",
      "Epoch 82/200\n",
      "1960/1960 [==============================] - 0s 67us/step - loss: 0.0189 - acc: 1.0000 - val_loss: 0.3442 - val_acc: 0.9167\n",
      "Epoch 83/200\n",
      "1960/1960 [==============================] - 0s 67us/step - loss: 0.0207 - acc: 1.0000 - val_loss: 0.3435 - val_acc: 0.9179\n",
      "Epoch 84/200\n",
      "1960/1960 [==============================] - 0s 66us/step - loss: 0.0229 - acc: 0.9995 - val_loss: 0.3428 - val_acc: 0.9179\n",
      "Epoch 85/200\n",
      "1960/1960 [==============================] - 0s 69us/step - loss: 0.0222 - acc: 0.9995 - val_loss: 0.3421 - val_acc: 0.9179\n",
      "Epoch 86/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0228 - acc: 0.9985 - val_loss: 0.3414 - val_acc: 0.9179\n",
      "Epoch 87/200\n",
      "1960/1960 [==============================] - 0s 67us/step - loss: 0.0228 - acc: 1.0000 - val_loss: 0.3407 - val_acc: 0.9190\n",
      "Epoch 88/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0215 - acc: 1.0000 - val_loss: 0.3401 - val_acc: 0.9202\n",
      "Epoch 89/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0219 - acc: 0.9995 - val_loss: 0.3395 - val_acc: 0.9202\n",
      "Epoch 90/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0208 - acc: 0.9990 - val_loss: 0.3388 - val_acc: 0.9202\n",
      "Epoch 91/200\n",
      "1960/1960 [==============================] - 0s 69us/step - loss: 0.0187 - acc: 0.9995 - val_loss: 0.3383 - val_acc: 0.9202\n",
      "Epoch 92/200\n",
      "1960/1960 [==============================] - 0s 67us/step - loss: 0.0234 - acc: 1.0000 - val_loss: 0.3377 - val_acc: 0.9202\n",
      "Epoch 93/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0202 - acc: 0.9995 - val_loss: 0.3371 - val_acc: 0.9214\n",
      "Epoch 94/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0190 - acc: 1.0000 - val_loss: 0.3366 - val_acc: 0.9214\n",
      "Epoch 95/200\n",
      "1960/1960 [==============================] - 0s 67us/step - loss: 0.0196 - acc: 0.9995 - val_loss: 0.3361 - val_acc: 0.9214\n",
      "Epoch 96/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0202 - acc: 0.9990 - val_loss: 0.3355 - val_acc: 0.9214\n",
      "Epoch 97/200\n",
      "1960/1960 [==============================] - 0s 67us/step - loss: 0.0204 - acc: 0.9990 - val_loss: 0.3350 - val_acc: 0.9214\n",
      "Epoch 98/200\n",
      "1960/1960 [==============================] - 0s 66us/step - loss: 0.0210 - acc: 0.9995 - val_loss: 0.3345 - val_acc: 0.9214\n",
      "Epoch 99/200\n",
      "1960/1960 [==============================] - 0s 65us/step - loss: 0.0208 - acc: 0.9990 - val_loss: 0.3340 - val_acc: 0.9226\n",
      "Epoch 100/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0204 - acc: 0.9990 - val_loss: 0.3335 - val_acc: 0.9226\n",
      "Epoch 101/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0208 - acc: 0.9995 - val_loss: 0.3331 - val_acc: 0.9226\n",
      "Epoch 102/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0208 - acc: 1.0000 - val_loss: 0.3326 - val_acc: 0.9226\n",
      "Epoch 103/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0184 - acc: 1.0000 - val_loss: 0.3321 - val_acc: 0.9226\n",
      "Epoch 104/200\n",
      "1960/1960 [==============================] - 0s 71us/step - loss: 0.0224 - acc: 0.9990 - val_loss: 0.3317 - val_acc: 0.9238\n",
      "Epoch 105/200\n",
      "1960/1960 [==============================] - 0s 80us/step - loss: 0.0204 - acc: 0.9995 - val_loss: 0.3313 - val_acc: 0.9238\n",
      "Epoch 106/200\n",
      "1960/1960 [==============================] - 0s 72us/step - loss: 0.0222 - acc: 1.0000 - val_loss: 0.3309 - val_acc: 0.9238\n",
      "Epoch 107/200\n",
      "1960/1960 [==============================] - 0s 69us/step - loss: 0.0187 - acc: 0.9995 - val_loss: 0.3305 - val_acc: 0.9238\n",
      "Epoch 108/200\n",
      "1960/1960 [==============================] - 0s 69us/step - loss: 0.0215 - acc: 0.9995 - val_loss: 0.3301 - val_acc: 0.9238\n",
      "Epoch 109/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0233 - acc: 0.9990 - val_loss: 0.3298 - val_acc: 0.9238\n",
      "Epoch 110/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0186 - acc: 0.9995 - val_loss: 0.3294 - val_acc: 0.9238\n",
      "Epoch 111/200\n",
      "1960/1960 [==============================] - 0s 69us/step - loss: 0.0230 - acc: 0.9985 - val_loss: 0.3290 - val_acc: 0.9238\n",
      "Epoch 112/200\n",
      "1960/1960 [==============================] - 0s 71us/step - loss: 0.0223 - acc: 0.9995 - val_loss: 0.3286 - val_acc: 0.9238\n",
      "Epoch 113/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0183 - acc: 1.0000 - val_loss: 0.3283 - val_acc: 0.9238\n",
      "Epoch 114/200\n",
      "1960/1960 [==============================] - 0s 74us/step - loss: 0.0209 - acc: 0.9990 - val_loss: 0.3279 - val_acc: 0.9238\n",
      "Epoch 115/200\n",
      "1960/1960 [==============================] - 0s 76us/step - loss: 0.0213 - acc: 0.9985 - val_loss: 0.3275 - val_acc: 0.9238\n",
      "Epoch 116/200\n",
      "1960/1960 [==============================] - 0s 91us/step - loss: 0.0221 - acc: 0.9990 - val_loss: 0.3271 - val_acc: 0.9238\n",
      "Epoch 117/200\n",
      "1960/1960 [==============================] - 0s 70us/step - loss: 0.0217 - acc: 0.9995 - val_loss: 0.3267 - val_acc: 0.9238\n",
      "Epoch 118/200\n",
      "1960/1960 [==============================] - 0s 78us/step - loss: 0.0228 - acc: 0.9990 - val_loss: 0.3264 - val_acc: 0.9238\n",
      "Epoch 119/200\n",
      "1960/1960 [==============================] - 0s 77us/step - loss: 0.0200 - acc: 1.0000 - val_loss: 0.3260 - val_acc: 0.9238\n",
      "Epoch 120/200\n",
      "1960/1960 [==============================] - 0s 75us/step - loss: 0.0199 - acc: 1.0000 - val_loss: 0.3256 - val_acc: 0.9238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0201 - acc: 0.9990 - val_loss: 0.3253 - val_acc: 0.9238\n",
      "Epoch 122/200\n",
      "1960/1960 [==============================] - 0s 71us/step - loss: 0.0204 - acc: 0.9995 - val_loss: 0.3250 - val_acc: 0.9238\n",
      "Epoch 123/200\n",
      "1960/1960 [==============================] - 0s 71us/step - loss: 0.0213 - acc: 0.9995 - val_loss: 0.3246 - val_acc: 0.9238\n",
      "Epoch 124/200\n",
      "1960/1960 [==============================] - 0s 74us/step - loss: 0.0204 - acc: 1.0000 - val_loss: 0.3243 - val_acc: 0.9238\n",
      "Epoch 125/200\n",
      "1960/1960 [==============================] - 0s 87us/step - loss: 0.0237 - acc: 0.9990 - val_loss: 0.3239 - val_acc: 0.9238\n",
      "Epoch 126/200\n",
      "1960/1960 [==============================] - 0s 74us/step - loss: 0.0228 - acc: 1.0000 - val_loss: 0.3236 - val_acc: 0.9238\n",
      "Epoch 127/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0207 - acc: 0.9995 - val_loss: 0.3233 - val_acc: 0.9238\n",
      "Epoch 128/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0219 - acc: 0.9990 - val_loss: 0.3230 - val_acc: 0.9238\n",
      "Epoch 129/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0203 - acc: 1.0000 - val_loss: 0.3226 - val_acc: 0.9250\n",
      "Epoch 130/200\n",
      "1960/1960 [==============================] - 0s 69us/step - loss: 0.0205 - acc: 0.9990 - val_loss: 0.3223 - val_acc: 0.9250\n",
      "Epoch 131/200\n",
      "1960/1960 [==============================] - 0s 75us/step - loss: 0.0184 - acc: 1.0000 - val_loss: 0.3219 - val_acc: 0.9250\n",
      "Epoch 132/200\n",
      "1960/1960 [==============================] - 0s 79us/step - loss: 0.0208 - acc: 0.9995 - val_loss: 0.3216 - val_acc: 0.9262\n",
      "Epoch 133/200\n",
      "1960/1960 [==============================] - 0s 72us/step - loss: 0.0212 - acc: 0.9990 - val_loss: 0.3213 - val_acc: 0.9262\n",
      "Epoch 134/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0217 - acc: 0.9995 - val_loss: 0.3210 - val_acc: 0.9262\n",
      "Epoch 135/200\n",
      "1960/1960 [==============================] - 0s 69us/step - loss: 0.0214 - acc: 0.9995 - val_loss: 0.3207 - val_acc: 0.9262\n",
      "Epoch 136/200\n",
      "1960/1960 [==============================] - 0s 66us/step - loss: 0.0199 - acc: 1.0000 - val_loss: 0.3205 - val_acc: 0.9262\n",
      "Epoch 137/200\n",
      "1960/1960 [==============================] - 0s 72us/step - loss: 0.0178 - acc: 1.0000 - val_loss: 0.3203 - val_acc: 0.9262\n",
      "Epoch 138/200\n",
      "1960/1960 [==============================] - 0s 67us/step - loss: 0.0215 - acc: 0.9995 - val_loss: 0.3200 - val_acc: 0.9262\n",
      "Epoch 139/200\n",
      "1960/1960 [==============================] - 0s 69us/step - loss: 0.0187 - acc: 1.0000 - val_loss: 0.3198 - val_acc: 0.9262\n",
      "Epoch 140/200\n",
      "1960/1960 [==============================] - 0s 71us/step - loss: 0.0197 - acc: 1.0000 - val_loss: 0.3195 - val_acc: 0.9262\n",
      "Epoch 141/200\n",
      "1960/1960 [==============================] - 0s 85us/step - loss: 0.0207 - acc: 1.0000 - val_loss: 0.3193 - val_acc: 0.9262\n",
      "Epoch 142/200\n",
      "1960/1960 [==============================] - 0s 83us/step - loss: 0.0217 - acc: 0.9995 - val_loss: 0.3190 - val_acc: 0.9262\n",
      "Epoch 143/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0188 - acc: 1.0000 - val_loss: 0.3188 - val_acc: 0.9262\n",
      "Epoch 144/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0218 - acc: 0.9995 - val_loss: 0.3185 - val_acc: 0.9262\n",
      "Epoch 145/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0193 - acc: 0.9995 - val_loss: 0.3183 - val_acc: 0.9262\n",
      "Epoch 146/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0206 - acc: 1.0000 - val_loss: 0.3181 - val_acc: 0.9262\n",
      "Epoch 147/200\n",
      "1960/1960 [==============================] - 0s 66us/step - loss: 0.0214 - acc: 0.9995 - val_loss: 0.3178 - val_acc: 0.9274\n",
      "Epoch 148/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0197 - acc: 0.9995 - val_loss: 0.3176 - val_acc: 0.9274\n",
      "Epoch 149/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0209 - acc: 0.9995 - val_loss: 0.3174 - val_acc: 0.9274\n",
      "Epoch 150/200\n",
      "1960/1960 [==============================] - 0s 76us/step - loss: 0.0214 - acc: 0.9990 - val_loss: 0.3172 - val_acc: 0.9274\n",
      "Epoch 151/200\n",
      "1960/1960 [==============================] - 0s 78us/step - loss: 0.0219 - acc: 1.0000 - val_loss: 0.3170 - val_acc: 0.9274\n",
      "Epoch 152/200\n",
      "1960/1960 [==============================] - 0s 76us/step - loss: 0.0199 - acc: 0.9985 - val_loss: 0.3168 - val_acc: 0.9274\n",
      "Epoch 153/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0204 - acc: 0.9995 - val_loss: 0.3166 - val_acc: 0.9274\n",
      "Epoch 154/200\n",
      "1960/1960 [==============================] - 0s 65us/step - loss: 0.0242 - acc: 0.9995 - val_loss: 0.3165 - val_acc: 0.9274\n",
      "Epoch 155/200\n",
      "1960/1960 [==============================] - 0s 67us/step - loss: 0.0204 - acc: 0.9985 - val_loss: 0.3163 - val_acc: 0.9274\n",
      "Epoch 156/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0179 - acc: 0.9990 - val_loss: 0.3160 - val_acc: 0.9274\n",
      "Epoch 157/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0197 - acc: 0.9995 - val_loss: 0.3158 - val_acc: 0.9274\n",
      "Epoch 158/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0201 - acc: 0.9995 - val_loss: 0.3157 - val_acc: 0.9274\n",
      "Epoch 159/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0221 - acc: 0.9985 - val_loss: 0.3155 - val_acc: 0.9274\n",
      "Epoch 160/200\n",
      "1960/1960 [==============================] - 0s 70us/step - loss: 0.0167 - acc: 1.0000 - val_loss: 0.3153 - val_acc: 0.9274\n",
      "Epoch 161/200\n",
      "1960/1960 [==============================] - 0s 67us/step - loss: 0.0195 - acc: 0.9995 - val_loss: 0.3152 - val_acc: 0.9274\n",
      "Epoch 162/200\n",
      "1960/1960 [==============================] - 0s 71us/step - loss: 0.0217 - acc: 0.9995 - val_loss: 0.3151 - val_acc: 0.9274\n",
      "Epoch 163/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0208 - acc: 0.9995 - val_loss: 0.3150 - val_acc: 0.9274\n",
      "Epoch 164/200\n",
      "1960/1960 [==============================] - 0s 67us/step - loss: 0.0172 - acc: 1.0000 - val_loss: 0.3149 - val_acc: 0.9274\n",
      "Epoch 165/200\n",
      "1960/1960 [==============================] - 0s 67us/step - loss: 0.0210 - acc: 1.0000 - val_loss: 0.3148 - val_acc: 0.9274\n",
      "Epoch 166/200\n",
      "1960/1960 [==============================] - 0s 69us/step - loss: 0.0209 - acc: 0.9985 - val_loss: 0.3146 - val_acc: 0.9274\n",
      "Epoch 167/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0210 - acc: 0.9995 - val_loss: 0.3145 - val_acc: 0.9274\n",
      "Epoch 168/200\n",
      "1960/1960 [==============================] - 0s 71us/step - loss: 0.0187 - acc: 0.9995 - val_loss: 0.3144 - val_acc: 0.9274\n",
      "Epoch 169/200\n",
      "1960/1960 [==============================] - 0s 80us/step - loss: 0.0212 - acc: 0.9980 - val_loss: 0.3143 - val_acc: 0.9274\n",
      "Epoch 170/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0191 - acc: 0.9995 - val_loss: 0.3142 - val_acc: 0.9274\n",
      "Epoch 171/200\n",
      "1960/1960 [==============================] - 0s 69us/step - loss: 0.0208 - acc: 0.9995 - val_loss: 0.3141 - val_acc: 0.9274\n",
      "Epoch 172/200\n",
      "1960/1960 [==============================] - 0s 67us/step - loss: 0.0186 - acc: 1.0000 - val_loss: 0.3140 - val_acc: 0.9274\n",
      "Epoch 173/200\n",
      "1960/1960 [==============================] - 0s 75us/step - loss: 0.0209 - acc: 1.0000 - val_loss: 0.3139 - val_acc: 0.9274\n",
      "Epoch 174/200\n",
      "1960/1960 [==============================] - 0s 84us/step - loss: 0.0201 - acc: 1.0000 - val_loss: 0.3138 - val_acc: 0.9274\n",
      "Epoch 175/200\n",
      "1960/1960 [==============================] - 0s 67us/step - loss: 0.0200 - acc: 0.9995 - val_loss: 0.3137 - val_acc: 0.9274\n",
      "Epoch 176/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0201 - acc: 0.9995 - val_loss: 0.3136 - val_acc: 0.9274\n",
      "Epoch 177/200\n",
      "1960/1960 [==============================] - 0s 69us/step - loss: 0.0211 - acc: 0.9990 - val_loss: 0.3134 - val_acc: 0.9274\n",
      "Epoch 178/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0200 - acc: 0.9995 - val_loss: 0.3133 - val_acc: 0.9274\n",
      "Epoch 179/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0221 - acc: 0.9990 - val_loss: 0.3132 - val_acc: 0.9274\n",
      "Epoch 180/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0222 - acc: 0.9995 - val_loss: 0.3131 - val_acc: 0.9274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0188 - acc: 1.0000 - val_loss: 0.3129 - val_acc: 0.9274\n",
      "Epoch 182/200\n",
      "1960/1960 [==============================] - 0s 67us/step - loss: 0.0218 - acc: 0.9995 - val_loss: 0.3128 - val_acc: 0.9286\n",
      "Epoch 183/200\n",
      "1960/1960 [==============================] - 0s 78us/step - loss: 0.0188 - acc: 1.0000 - val_loss: 0.3127 - val_acc: 0.9286\n",
      "Epoch 184/200\n",
      "1960/1960 [==============================] - 0s 70us/step - loss: 0.0203 - acc: 0.9995 - val_loss: 0.3126 - val_acc: 0.9298\n",
      "Epoch 185/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0214 - acc: 0.9985 - val_loss: 0.3125 - val_acc: 0.9286\n",
      "Epoch 186/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0238 - acc: 0.9990 - val_loss: 0.3124 - val_acc: 0.9286\n",
      "Epoch 187/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0204 - acc: 0.9980 - val_loss: 0.3123 - val_acc: 0.9286\n",
      "Epoch 188/200\n",
      "1960/1960 [==============================] - 0s 69us/step - loss: 0.0207 - acc: 1.0000 - val_loss: 0.3122 - val_acc: 0.9286\n",
      "Epoch 189/200\n",
      "1960/1960 [==============================] - 0s 67us/step - loss: 0.0190 - acc: 0.9995 - val_loss: 0.3121 - val_acc: 0.9286\n",
      "Epoch 190/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0186 - acc: 0.9990 - val_loss: 0.3120 - val_acc: 0.9286\n",
      "Epoch 191/200\n",
      "1960/1960 [==============================] - 0s 75us/step - loss: 0.0204 - acc: 0.9990 - val_loss: 0.3118 - val_acc: 0.9286\n",
      "Epoch 192/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0197 - acc: 1.0000 - val_loss: 0.3118 - val_acc: 0.9286\n",
      "Epoch 193/200\n",
      "1960/1960 [==============================] - 0s 67us/step - loss: 0.0208 - acc: 0.9990 - val_loss: 0.3117 - val_acc: 0.9286\n",
      "Epoch 194/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0218 - acc: 0.9995 - val_loss: 0.3116 - val_acc: 0.9286\n",
      "Epoch 195/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0197 - acc: 0.9995 - val_loss: 0.3115 - val_acc: 0.9286\n",
      "Epoch 196/200\n",
      "1960/1960 [==============================] - 0s 67us/step - loss: 0.0188 - acc: 0.9995 - val_loss: 0.3114 - val_acc: 0.9286\n",
      "Epoch 197/200\n",
      "1960/1960 [==============================] - 0s 66us/step - loss: 0.0194 - acc: 1.0000 - val_loss: 0.3113 - val_acc: 0.9286\n",
      "Epoch 198/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0186 - acc: 1.0000 - val_loss: 0.3112 - val_acc: 0.9286\n",
      "Epoch 199/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0217 - acc: 0.9995 - val_loss: 0.3111 - val_acc: 0.9274\n",
      "Epoch 200/200\n",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0191 - acc: 0.9995 - val_loss: 0.3110 - val_acc: 0.9274\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "lr = 1e-3\n",
    "AR_single.compile(loss=\"categorical_crossentropy\",optimizer=adam(lr),metrics=['accuracy'])\n",
    "lrScheduler = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, cooldown=5, min_lr=1e-5)\n",
    "history=AR_single.fit([X_0,X_1],Y,\n",
    "        batch_size=len(Y),\n",
    "        epochs=200,\n",
    "        verbose=True,\n",
    "        shuffle=True,\n",
    "        callbacks=[lrScheduler],\n",
    "        validation_data=([X_test_0,X_test_1],Y_test)      \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AR_single.save_weights('weights/coarse_heavy.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f88a11ca5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With frame_sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-6\n",
    "AR_single.compile(loss=\"categorical_crossentropy\",optimizer=adam(lr),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 13/1960 [00:00<00:15, 127.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fan/anaconda3/envs/keras/lib/python3.6/site-packages/scipy/ndimage/interpolation.py:583: UserWarning: From scipy 0.13.0, the output shape of zoom() is calculated with round() instead of int() - for these inputs the size of the returned array has changed.\n",
      "  \"the returned array has changed.\", UserWarning)\n",
      "100%|██████████| 1960/1960 [00:06<00:00, 289.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/1\n",
      "1960/1960 [==============================] - 6s 3ms/step - loss: 0.0540 - acc: 0.9918 - val_loss: 0.3109 - val_acc: 0.9274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 18/1960 [00:00<00:11, 176.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:06<00:00, 291.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/1\n",
      "\r",
      "1960/1960 [==============================] - 0s 94us/step - loss: 0.0632 - acc: 0.9893 - val_loss: 0.3111 - val_acc: 0.9274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1960 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:07<00:00, 275.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/1\n",
      "\r",
      "1960/1960 [==============================] - 0s 88us/step - loss: 0.0516 - acc: 0.9888 - val_loss: 0.3113 - val_acc: 0.9274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1960 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:06<00:00, 300.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/1\n",
      "\r",
      "1960/1960 [==============================] - 0s 81us/step - loss: 0.0568 - acc: 0.9898 - val_loss: 0.3113 - val_acc: 0.9286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1960 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:06<00:00, 298.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/1\n",
      "\r",
      "1960/1960 [==============================] - 0s 72us/step - loss: 0.0507 - acc: 0.9913 - val_loss: 0.3112 - val_acc: 0.9298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1960 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:06<00:00, 298.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/1\n",
      "\r",
      "1960/1960 [==============================] - 0s 64us/step - loss: 0.0590 - acc: 0.9878 - val_loss: 0.3114 - val_acc: 0.9298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1960 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:06<00:00, 298.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/1\n",
      "\r",
      "1960/1960 [==============================] - 0s 64us/step - loss: 0.0577 - acc: 0.9888 - val_loss: 0.3115 - val_acc: 0.9298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1960 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:06<00:00, 300.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/1\n",
      "\r",
      "1960/1960 [==============================] - 0s 85us/step - loss: 0.0647 - acc: 0.9888 - val_loss: 0.3118 - val_acc: 0.9298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1960 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:06<00:00, 303.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/1\n",
      "\r",
      "1960/1960 [==============================] - 0s 67us/step - loss: 0.0513 - acc: 0.9908 - val_loss: 0.3122 - val_acc: 0.9298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1960 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:06<00:00, 311.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/1\n",
      "\r",
      "1960/1960 [==============================] - 0s 74us/step - loss: 0.0601 - acc: 0.9913 - val_loss: 0.3125 - val_acc: 0.9298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1960 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:06<00:00, 297.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/1\n",
      "\r",
      "1960/1960 [==============================] - 0s 66us/step - loss: 0.0576 - acc: 0.9878 - val_loss: 0.3129 - val_acc: 0.9286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 18/1960 [00:00<00:11, 175.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:06<00:00, 300.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/1\n",
      "\r",
      "1960/1960 [==============================] - 0s 65us/step - loss: 0.0460 - acc: 0.9923 - val_loss: 0.3132 - val_acc: 0.9274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1960 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:06<00:00, 298.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/1\n",
      "\r",
      "1960/1960 [==============================] - 0s 65us/step - loss: 0.0584 - acc: 0.9888 - val_loss: 0.3135 - val_acc: 0.9274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1960 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:06<00:00, 299.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/1\n",
      "\r",
      "1960/1960 [==============================] - 0s 79us/step - loss: 0.0615 - acc: 0.9878 - val_loss: 0.3138 - val_acc: 0.9274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1960 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:06<00:00, 298.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/1\n",
      "\r",
      "1960/1960 [==============================] - 0s 69us/step - loss: 0.0489 - acc: 0.9908 - val_loss: 0.3140 - val_acc: 0.9274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1960 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:06<00:00, 294.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/1\n",
      "\r",
      "1960/1960 [==============================] - 0s 65us/step - loss: 0.0556 - acc: 0.9888 - val_loss: 0.3142 - val_acc: 0.9274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1960 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:06<00:00, 296.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/1\n",
      "\r",
      "1960/1960 [==============================] - 0s 71us/step - loss: 0.0546 - acc: 0.9913 - val_loss: 0.3145 - val_acc: 0.9274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1960 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:06<00:00, 298.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/1\n",
      "\r",
      "1960/1960 [==============================] - 0s 64us/step - loss: 0.0442 - acc: 0.9939 - val_loss: 0.3146 - val_acc: 0.9274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1960 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:06<00:00, 290.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/1\n",
      "\r",
      "1960/1960 [==============================] - 0s 65us/step - loss: 0.0567 - acc: 0.9872 - val_loss: 0.3147 - val_acc: 0.9274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1960 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:06<00:00, 311.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/1\n",
      "\r",
      "1960/1960 [==============================] - 0s 64us/step - loss: 0.0606 - acc: 0.9878 - val_loss: 0.3149 - val_acc: 0.9274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1960 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:06<00:00, 315.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/1\n",
      "\r",
      "1960/1960 [==============================] - 0s 78us/step - loss: 0.0582 - acc: 0.9898 - val_loss: 0.3152 - val_acc: 0.9274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 18/1960 [00:00<00:11, 176.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:06<00:00, 307.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/1\n",
      "\r",
      "1960/1960 [==============================] - 0s 69us/step - loss: 0.0484 - acc: 0.9923 - val_loss: 0.3155 - val_acc: 0.9262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1960 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:06<00:00, 310.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/1\n",
      "\r",
      "1960/1960 [==============================] - 0s 67us/step - loss: 0.0518 - acc: 0.9913 - val_loss: 0.3157 - val_acc: 0.9262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1960 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:06<00:00, 311.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/1\n",
      "\r",
      "1960/1960 [==============================] - 0s 64us/step - loss: 0.0489 - acc: 0.9949 - val_loss: 0.3160 - val_acc: 0.9250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1960 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:06<00:00, 315.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/1\n",
      "\r",
      "1960/1960 [==============================] - 0s 75us/step - loss: 0.0475 - acc: 0.9918 - val_loss: 0.3163 - val_acc: 0.9250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1960 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:06<00:00, 310.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/1\n",
      "\r",
      "1960/1960 [==============================] - 0s 64us/step - loss: 0.0538 - acc: 0.9908 - val_loss: 0.3166 - val_acc: 0.9250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1960 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:06<00:00, 309.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/1\n",
      "\r",
      "1960/1960 [==============================] - 0s 64us/step - loss: 0.0479 - acc: 0.9918 - val_loss: 0.3169 - val_acc: 0.9250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1960 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:06<00:00, 306.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/1\n",
      "\r",
      "1960/1960 [==============================] - 0s 65us/step - loss: 0.0456 - acc: 0.9918 - val_loss: 0.3171 - val_acc: 0.9250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1960 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:06<00:00, 310.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/1\n",
      "\r",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0474 - acc: 0.9934 - val_loss: 0.3174 - val_acc: 0.9250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1960 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:06<00:00, 283.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/1\n",
      "\r",
      "1960/1960 [==============================] - 0s 87us/step - loss: 0.0505 - acc: 0.9903 - val_loss: 0.3175 - val_acc: 0.9250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1960 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:06<00:00, 310.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/1\n",
      "\r",
      "1960/1960 [==============================] - 0s 64us/step - loss: 0.0394 - acc: 0.9934 - val_loss: 0.3176 - val_acc: 0.9250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 18/1960 [00:00<00:10, 179.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:06<00:00, 306.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/1\n",
      "\r",
      "1960/1960 [==============================] - 0s 64us/step - loss: 0.0560 - acc: 0.9908 - val_loss: 0.3176 - val_acc: 0.9250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1960 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:06<00:00, 302.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/1\n",
      "\r",
      "1960/1960 [==============================] - 0s 72us/step - loss: 0.0552 - acc: 0.9883 - val_loss: 0.3177 - val_acc: 0.9250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1960 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:06<00:00, 300.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/1\n",
      "\r",
      "1960/1960 [==============================] - 0s 64us/step - loss: 0.0458 - acc: 0.9903 - val_loss: 0.3177 - val_acc: 0.9250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1960 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:06<00:00, 294.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/1\n",
      "\r",
      "1960/1960 [==============================] - 0s 64us/step - loss: 0.0511 - acc: 0.9929 - val_loss: 0.3178 - val_acc: 0.9250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1960 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:06<00:00, 299.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/1\n",
      "\r",
      "1960/1960 [==============================] - 0s 69us/step - loss: 0.0552 - acc: 0.9903 - val_loss: 0.3179 - val_acc: 0.9250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1960 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:06<00:00, 295.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/1\n",
      "\r",
      "1960/1960 [==============================] - 0s 91us/step - loss: 0.0424 - acc: 0.9923 - val_loss: 0.3179 - val_acc: 0.9250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1960 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:06<00:00, 305.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/1\n",
      "\r",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0632 - acc: 0.9862 - val_loss: 0.3180 - val_acc: 0.9250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1960 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:06<00:00, 303.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/1\n",
      "\r",
      "1960/1960 [==============================] - 0s 66us/step - loss: 0.0448 - acc: 0.9929 - val_loss: 0.3181 - val_acc: 0.9250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1960 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:06<00:00, 303.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/1\n",
      "\r",
      "1960/1960 [==============================] - 0s 67us/step - loss: 0.0611 - acc: 0.9872 - val_loss: 0.3181 - val_acc: 0.9250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1960 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:06<00:00, 303.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/1\n",
      "\r",
      "1960/1960 [==============================] - 0s 72us/step - loss: 0.0540 - acc: 0.9878 - val_loss: 0.3180 - val_acc: 0.9250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 18/1960 [00:00<00:10, 178.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:06<00:00, 311.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/1\n",
      "\r",
      "1960/1960 [==============================] - 0s 64us/step - loss: 0.0634 - acc: 0.9883 - val_loss: 0.3179 - val_acc: 0.9250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1960 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:06<00:00, 312.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/1\n",
      "\r",
      "1960/1960 [==============================] - 0s 68us/step - loss: 0.0631 - acc: 0.9898 - val_loss: 0.3179 - val_acc: 0.9250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1960 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:06<00:00, 305.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/1\n",
      "\r",
      "1960/1960 [==============================] - 0s 69us/step - loss: 0.0502 - acc: 0.9888 - val_loss: 0.3179 - val_acc: 0.9250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1960 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:06<00:00, 312.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/1\n",
      "\r",
      "1960/1960 [==============================] - 0s 66us/step - loss: 0.0450 - acc: 0.9908 - val_loss: 0.3178 - val_acc: 0.9250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1960 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:06<00:00, 313.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/1\n",
      "\r",
      "1960/1960 [==============================] - 0s 81us/step - loss: 0.0544 - acc: 0.9878 - val_loss: 0.3177 - val_acc: 0.9250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1960 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:06<00:00, 314.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/1\n",
      "\r",
      "1960/1960 [==============================] - 0s 64us/step - loss: 0.0385 - acc: 0.9944 - val_loss: 0.3175 - val_acc: 0.9250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1960 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:06<00:00, 294.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/1\n",
      "\r",
      "1960/1960 [==============================] - 0s 64us/step - loss: 0.0479 - acc: 0.9929 - val_loss: 0.3175 - val_acc: 0.9250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1960 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:06<00:00, 288.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/1\n",
      "\r",
      "1960/1960 [==============================] - 0s 71us/step - loss: 0.0562 - acc: 0.9908 - val_loss: 0.3174 - val_acc: 0.9250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1960 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:06<00:00, 299.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/1\n",
      "\r",
      "1960/1960 [==============================] - 0s 67us/step - loss: 0.0488 - acc: 0.9929 - val_loss: 0.3173 - val_acc: 0.9250\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "for e in range(epochs):\n",
    "    print('epoch{}'.format(e))\n",
    "    X_0 = []\n",
    "    X_1 = []\n",
    "    Y = []\n",
    "    \n",
    "    for i in tqdm(range(len(Train['pose']))): \n",
    "    #for i in range(len(Train['pose'])): \n",
    "    \n",
    "        label = np.zeros(C.clc_coarse)\n",
    "        label[Train['coarse_label'][i]-1] = 1 \n",
    "        \n",
    "        p = np.copy(Train['pose'][i]).reshape([-1,22,3])[:,C.joint_ind,:]\n",
    "        p = sampling_frame(p,C)\n",
    "       \n",
    "        #rotation\n",
    "        x_angle = np.random.uniform(-0.2,0.2)\n",
    "        y_angle = np.random.uniform(-0.2,0.2)\n",
    "        z_angle = np.random.uniform(-0.2,0.2)\n",
    "        R = euler2mat(x_angle, y_angle, z_angle, 'sxyz')\n",
    "        p = rotaion_one(p,R)\n",
    "         \n",
    "        p[:,:,0] = p[:,:,0]*random.uniform(0.9, 1.1)+p[:,:,0]*random.uniform(-0.1,0.1)\n",
    "        p[:,:,1] = p[:,:,1]*random.uniform(0.9, 1.1)+p[:,:,1]*random.uniform(-0.1,0.1)\n",
    "        p[:,:,2] = p[:,:,2]*random.uniform(0.9, 1.1)+p[:,:,2]*random.uniform(-0.1,0.1)\n",
    "     \n",
    "        p = normlize_range(p)\n",
    "        M = get_CG(p,C)\n",
    "        \n",
    "        X_0.append(M)\n",
    "        X_1.append(p)\n",
    "        Y.append(label)\n",
    "\n",
    "    X_0 = np.stack(X_0)  \n",
    "    X_1 = np.stack(X_1) \n",
    "    Y = np.stack(Y)\n",
    "   \n",
    "\n",
    "    AR_single.fit([X_0,X_1],Y,\n",
    "            batch_size=len(Y),\n",
    "            epochs=1,\n",
    "            verbose=True,\n",
    "            shuffle=True,\n",
    "            validation_data=([X_test_0,X_test_1],Y_test)      \n",
    "            )\n",
    "\n",
    "    if e%10==0:\n",
    "        AR_single.save_weights('weights/coarse_1D_heavy_aug.h5')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkUAAAJCCAYAAADOe7N5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFcVJREFUeJzt3G+Mrndd5/H3l05bOICCwbBCUdgE2RC0izlRECMJ1WxZ\nifhg3UBWg6tJH7gqGhMD8YHPNiYao4muposIiQSzWzESo0gX/BM3QKyI8qcqBLUUWwr+w3jW9gz9\n7YMzu6m1Q09n7jPXTPt6Jc2Z+z73zPXJdc7Mefeae+5ZawUA8Fj3uK0HAACcBqIIACBRBABQiSIA\ngEoUAQBUoggAoBJFAACVKAIAqEQRAEBVeyd5sCc85dr15Gc86SQPedn+6Xav7H0ks/UAdsqnAfAo\n9A/97WfWWl/8cI870Sh68jOe1H/8xX93koe8bH96/uLWE86k2TvRv0JcYWt/f+sJADv3v9Ytf3k5\nj/PtMwCARBEAQCWKAAAqUQQAUIkiAIBKFAEAVKIIAKASRQAAlSgCAKhEEQBAJYoAACpRBABQiSIA\ngEoUAQBUx4yimblxZv50Zj42M6/b1SgAgJN25Ciamauqn6leXj2/evXMPH9XwwAATtJxrhR9dfWx\ntdbH11r3Vb9UvXI3swAATtZxouiZ1ScecPvOg/sAAM6cK/5E65m5aWZum5nb/s/f/tOVPhwAwJEc\nJ4o+WT3rAbevO7jvn1lr3bzWOr/WOv+Epz7+GIcDALhyjhNFv189d2aeMzPXVK+q3r6bWQAAJ2vv\nqO+41tqfme+pfrO6qnrjWuvDO1sGAHCCjhxFVWutX69+fUdbAAA24xWtAQASRQAAlSgCAKhEEQBA\nJYoAACpRBABQiSIAgEoUAQBUoggAoBJFAACVKAIAqEQRAEAligAAKlEEAFDV3kke7N6PPq6P3fgF\nJ3nIy3bt71y99YRD3XfDZ7aecObMNddsPeFQ91+4sPUEHkNm70S/zD8ia39/6wns0Gn+u9bFy3uY\nK0UAAIkiAIBKFAEAVKIIAKASRQAAlSgCAKhEEQBAJYoAACpRBABQiSIAgEoUAQBUoggAoBJFAACV\nKAIAqEQRAEAligAAKlEEAFCJIgCAShQBAFSiCACgEkUAAJUoAgCoRBEAQCWKAAAqUQQAUIkiAIBK\nFAEAVKIIAKASRQAAlSgCAKhEEQBAJYoAACpRBABQiSIAgEoUAQBUoggAoBJFAACVKAIAqGrvJA+2\n9j/X5z7z1yd5yMu2Xn5u6wmHuuZdT9t6wqHufendW094SGt/f+sJPIY87tzp/fpx/4ULW0/gMeLR\n8HXXlSIAgEQRAEAligAAKlEEAFCJIgCAShQBAFSiCACgEkUAAJUoAgCoRBEAQCWKAAAqUQQAUIki\nAIBKFAEAVKIIAKA6RhTNzLNm5rdm5iMz8+GZee0uhwEAnKS9Y7zvfvWDa633z8yTqz+YmVvXWh/Z\n0TYAgBNz5CtFa6271lrvP3j7H6rbq2fuahgAwEk6zpWi/29mnl29sHrfQ/zeTdVNVY/v3C4OBwCw\nc8d+ovXMPKn65er711qfffDvr7VuXmudX2udv7prj3s4AIAr4lhRNDNXdymI3rLWettuJgEAnLzj\n/PTZVD9f3b7W+ondTQIAOHnHuVL0kurbq5fNzAcO/vv3O9oFAHCijvxE67XW71Wzwy0AAJvxitYA\nAIkiAIBKFAEAVKIIAKASRQAAlSgCAKhEEQBAJYoAACpRBABQiSIAgEoUAQBUoggAoBJFAABV7Z3k\nweaaq9v7V9ed5CEv2+fuunvrCYe696Wnd9sd//Mrtp7wkL70Wz+49QQeQ+6/cGHrCcAOuFIEAJAo\nAgCoRBEAQCWKAAAqUQQAUIkiAIBKFAEAVKIIAKASRQAAlSgCAKhEEQBAJYoAACpRBABQiSIAgEoU\nAQBUoggAoBJFAACVKAIAqEQRAEAligAAKlEEAFCJIgCAShQBAFSiCACgEkUAAJUoAgCoRBEAQCWK\nAAAqUQQAUIkiAIBKFAEAVKIIAKASRQAAlSgCAKhEEQBAJYoAACpRBABQiSIAgKr2TvJg676L7X/i\nzpM8JFfYl37rB7ee8JCe/p4v2HrCoT714s9uPeFQs3eiXxIekbW/v/UE4PM4zV8/unh5D3OlCAAg\nUQQAUIkiAIBKFAEAVKIIAKASRQAAlSgCAKhEEQBAJYoAACpRBABQiSIAgEoUAQBUoggAoBJFAACV\nKAIAqHYQRTNz1cz84cz82i4GAQBsYRdXil5b3b6DjwMAsJljRdHMXFd9U/WG3cwBANjGca8U/WT1\nQ9X9O9gCALCZI0fRzLyiumet9QcP87ibZua2mbntYvce9XAAAFfUca4UvaT65pn5i+qXqpfNzC8+\n+EFrrZvXWufXWuev7tpjHA4A4Mo5chSttV6/1rpurfXs6lXVu9da37azZQAAJ8jrFAEAVHu7+CBr\nrd+ufnsXHwsAYAuuFAEAJIoAACpRBABQiSIAgEoUAQBUoggAoBJFAACVKAIAqEQRAEAligAAKlEE\nAFCJIgCAShQBAFSiCACgqr2tB8CV8KkXf3brCYd60R9d3HrCod57/dYLDjd7p/fL1drf33oCbO7R\n8HngShEAQKIIAKASRQAAlSgCAKhEEQBAJYoAACpRBABQiSIAgEoUAQBUoggAoBJFAACVKAIAqEQR\nAEAligAAKlEEAFCJIgCAShQBAFSiCACgEkUAAJUoAgCoRBEAQCWKAAAqUQQAUIkiAIBKFAEAVKII\nAKASRQAAlSgCAKhEEQBAJYoAACpRBABQiSIAgEoUAQBUoggAoBJFAACVKAIAqEQRAEAligAAqtrb\negA81rz3+qu3nnCom/7s41tPONTNX/6vt54APMq5UgQAkCgCAKhEEQBAJYoAACpRBABQiSIAgEoU\nAQBUoggAoBJFAACVKAIAqEQRAEAligAAKlEEAFCJIgCAShQBAFTHjKKZecrM3DIzfzIzt8/Mi3c1\nDADgJO0d8/1/qnrHWus/zMw11bkdbAIAOHFHjqKZ+cLq66vvqFpr3Vfdt5tZAAAn6zjfPntO9enq\nF2bmD2fmDTPzxB3tAgA4UceJor3qq6qfXWu9sPrH6nUPftDM3DQzt83MbRe79xiHAwC4co4TRXdW\nd6613ndw+5YuRdI/s9a6ea11fq11/uquPcbhAACunCNH0Vrr7uoTM/O8g7tuqD6yk1UAACfsuD99\n9r3VWw5+8uzj1X8+/iQAgJN3rChaa32gOr+jLQAAm/GK1gAAiSIAgEoUAQBUoggAoBJFAACVKAIA\nqEQRAEAligAAKlEEAFCJIgCAShQBAFSiCACgEkUAAJUoAgCoam/rAXAlPO7cua0nHOr+Cxe2nnCo\n//78L996wqGu/Z2nbT3hUPe+9O6tJwA74EoRAECiCACgEkUAAJUoAgCoRBEAQCWKAAAqUQQAUIki\nAIBKFAEAVKIIAKASRQAAlSgCAKhEEQBAJYoAACpRBABQiSIAgEoUAQBUoggAoBJFAACVKAIAqEQR\nAEAligAAKlEEAFCJIgCAShQBAFSiCACgEkUAAJUoAgCoRBEAQCWKAAAqUQQAUIkiAIBKFAEAVKII\nAKASRQAAlSgCAKhEEQBAJYoAAKra23rAafG4c+e2nnCoOfeErScc6nOf+eutJzyk+y9c2HrCoWbv\n9H7arf39rScc6t6X3r31hEO9/MN/t/WEQ73j+qdtPeFQp/nvG4/caf7a1sXLe5grRQAAiSIAgEoU\nAQBUoggAoBJFAACVKAIAqEQRAEAligAAKlEEAFCJIgCAShQBAFSiCACgEkUAAJUoAgCoRBEAQHXM\nKJqZH5iZD8/Mh2bmrTPz+F0NAwA4SUeOopl5ZvV91fm11guqq6pX7WoYAMBJOu63z/aqJ8zMXnWu\n+qvjTwIAOHlHjqK11ierH6/uqO6q/n6t9c4HP25mbpqZ22bmtovde/SlAABX0HG+ffbU6pXVc6pn\nVE+cmW978OPWWjevtc6vtc5f3bVHXwoAcAUd59tn31D9+Vrr02uti9Xbqq/dzSwAgJN1nCi6o3rR\nzJybmaluqG7fzSwAgJN1nOcUva+6pXp/9cGDj3XzjnYBAJyoveO881rrR6of2dEWAIDNeEVrAIBE\nEQBAJYoAACpRBABQiSIAgEoUAQBUoggAoBJFAACVKAIAqEQRAEAligAAKlEEAFCJIgCAShQBAFS1\nt/UAHt7nPvPXW0841OPOndt6wkO6/8KFrSfwGPKO65+29YRDPet/X7v1hEPd8TX7W084c2bv9P6z\nvfbP/p+nK0UAAIkiAIBKFAEAVKIIAKASRQAAlSgCAKhEEQBAJYoAACpRBABQiSIAgEoUAQBUoggA\noBJFAACVKAIAqEQRAEAligAAKlEEAFCJIgCAShQBAFSiCACgEkUAAJUoAgCoRBEAQCWKAAAqUQQA\nUIkiAIBKFAEAVKIIAKASRQAAlSgCAKhEEQBAJYoAACpRBABQiSIAgEoUAQBUoggAoBJFAABV7W09\n4LS4/8KFrSecSeu++7aecOas/f2tJ7Bjp/nP9I6vOb3b/ttf/t7WEx7Sd3/Z1209gY24UgQAkCgC\nAKhEEQBAJYoAACpRBABQiSIAgEoUAQBUoggAoBJFAACVKAIAqEQRAEAligAAKlEEAFCJIgCAShQB\nAFSXEUUz88aZuWdmPvSA+75oZm6dmY8e/PrUKzsTAODKupwrRW+qbnzQfa+r3rXWem71roPbAABn\n1sNG0Vrrd6u/edDdr6zefPD2m6tv2fEuAIATddTnFD19rXXXwdt3V0/f0R4AgE0c+4nWa61VrcN+\nf2ZumpnbZua2i9173MMBAFwRR42iT83Ml1Qd/HrPYQ9ca9281jq/1jp/ddce8XAAAFfWUaPo7dVr\nDt5+TfWru5kDALCNy/mR/LdW76meNzN3zsx3VT9afePMfLT6hoPbAABn1t7DPWCt9epDfuuGHW8B\nANiMV7QGAEgUAQBUoggAoBJFAACVKAIAqEQRAEAligAAKlEEAFCJIgCAShQBAFSiCACgEkUAAJUo\nAgCoRBEAQFV7Ww/gbFv7+1tPAM6o7/6yr9t6wkN60R9d3HrCod57/dYLHt1cKQIASBQBAFSiCACg\nEkUAAJUoAgCoRBEAQCWKAAAqUQQAUIkiAIBKFAEAVKIIAKASRQAAlSgCAKhEEQBAJYoAACpRBABQ\niSIAgEoUAQBUoggAoBJFAACVKAIAqEQRAEAligAAKlEEAFCJIgCAShQBAFSiCACgEkUAAJUoAgCo\nRBEAQCWKAAAqUQQAUIkiAIBKFAEAVKIIAKASRQAAlSgCAKhEEQBAVXtbDwCA0+S911+99YRDveyD\n/7j1hEO9+yueuPWEY3OlCAAgUQQAUIkiAIBKFAEAVKIIAKASRQAAlSgCAKhEEQBAJYoAACpRBABQ\niSIAgEoUAQBUoggAoBJFAACVKAIAqC4jimbmjTNzz8x86AH3/djM/MnM/PHM/MrMPOXKzgQAuLIu\n50rRm6obH3TfrdUL1lpfWf1Z9fod7wIAOFEPG0Vrrd+t/uZB971zrbV/cPO91XVXYBsAwInZxXOK\nvrP6jR18HACAzewd551n5oer/eotn+cxN1U3VT2+c8c5HADAFXPkKJqZ76heUd2w1lqHPW6tdXN1\nc9UXzBcd+jgAgC0dKYpm5sbqh6qXrrUu7HYSAMDJu5wfyX9r9Z7qeTNz58x8V/XT1ZOrW2fmAzPz\nc1d4JwDAFfWwV4rWWq9+iLt//gpsAQDYjFe0BgBIFAEAVKIIAKASRQAAlSgCAKhEEQBAJYoAACpR\nBABQiSIAgEoUAQBUoggAoBJFAACVKAIAqEQRAEBVe1sP4OHN3un9Y1r7+1tPeEjOGfBo9O6veOLW\nEw71m3/1ga0nHOqqL7m8x7lSBACQKAIAqEQRAEAligAAKlEEAFCJIgCAShQBAFSiCACgEkUAAJUo\nAgCoRBEAQCWKAAAqUQQAUIkiAIBKFAEAVKIIAKASRQAAlSgCAKhEEQBAJYoAACpRBABQiSIAgEoU\nAQBUoggAoBJFAACVKAIAqEQRAEAligAAKlEEAFCJIgCAShQBAFSiCACgEkUAAJUoAgCoRBEAQCWK\nAAAqUQQAUIkiAICqZq11cgeb+XT1lzv6cE+rPrOjj/VY4rwdjfP2yDlnR+O8HY3z9sg9ls7Zl621\nvvjhHnSiUbRLM3PbWuv81jvOGuftaJy3R845Oxrn7Wict0fOOfuXfPsMACBRBABQne0ounnrAWeU\n83Y0ztsj55wdjfN2NM7bI+ecPciZfU4RAMAuneUrRQAAO3Mmo2hmbpyZP52Zj83M67becxbMzLNm\n5rdm5iMz8+GZee3Wm86KmblqZv5wZn5t6y1nxcw8ZWZumZk/mZnbZ+bFW2867WbmBw4+Nz80M2+d\nmcdvvek0mpk3zsw9M/OhB9z3RTNz68x89ODXp2658TQ65Lz92MHn6B/PzK/MzFO23HganLkompmr\nqp+pXl49v3r1zDx/21Vnwn71g2ut51cvqv6L83bZXlvdvvWIM+anqnestf5NdX3O3+c1M8+svq86\nv9Z6QXVV9aptV51ab6pufNB9r6vetdZ6bvWug9v8c2/qX563W6sXrLW+svqz6vUnPeq0OXNRVH11\n9bG11sfXWvdVv1S9cuNNp95a66611vsP3v6HLv0j9cxtV51+M3Nd9U3VG7beclbMzBdWX1/9fNVa\n67611t9tu+pM2KueMDN71bnqrzbecyqttX63+psH3f3K6s0Hb7+5+pYTHXUGPNR5W2u9c621f3Dz\nvdV1Jz7slDmLUfTM6hMPuH1n/nF/RGbm2dULq/dtu+RM+Mnqh6r7tx5yhjyn+nT1CwffdnzDzDxx\n61Gn2Vrrk9WPV3dUd1V/v9Z657arzpSnr7XuOnj77urpW445o76z+o2tR2ztLEYRxzAzT6p+ufr+\ntdZnt95zms3MK6p71lp/sPWWM2av+qrqZ9daL6z+Md/O+LwOngPzyi4F5TOqJ87Mt2276mxal36k\n2o9VPwIz88NdeorFW7besrWzGEWfrJ71gNvXHdzHw5iZq7sURG9Za71t6z1nwEuqb56Zv+jSt2lf\nNjO/uO2kM+HO6s611v+7EnlLlyKJw31D9edrrU+vtS5Wb6u+duNNZ8mnZuZLqg5+vWfjPWfGzHxH\n9YrqPy2v0XMmo+j3q+fOzHNm5pouPRnx7RtvOvVmZrr0HI/b11o/sfWes2Ct9fq11nVrrWd36e/Z\nu9da/u/9Yay17q4+MTPPO7jrhuojG046C+6oXjQz5w4+V2/Ik9MfibdXrzl4+zXVr2645cyYmRu7\n9PSAb15rXdh6z2lw5qLo4Elh31P9Zpe+aPyPtdaHt111Jryk+vYuXe34wMF//37rUTxqfW/1lpn5\n4+rfVv914z2n2sFVtVuq91cf7NLXZq82/BBm5q3Ve6rnzcydM/Nd1Y9W3zgzH+3SVbcf3XLjaXTI\nefvp6snVrQf/JvzcpiNPAa9oDQDQGbxSBABwJYgiAIBEEQBAJYoAACpRBABQiSIAgEoUAQBUoggA\noKr/Cxz3YstmFndgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f88c81d8d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "Y_pred = AR_single.predict([X_test_0,X_test_1])\n",
    "cnf_matrix = confusion_matrix(np.argmax(Y_test,axis=1),np.argmax(Y_pred,axis=1))\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(cnf_matrix)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
